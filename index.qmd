---
title: "扩散先验在类超声阴影缺失逆问题中的应用"
author: "马忠慧 (学号：25113060024)"
date: last-modified
format:
  html:
    number-sections: true
    toc: true
    code-tools: true
    theme: cosmo
---

<style>
  /* 1. 全局段落缩进 2 字符，并设置两端对齐 */
  p {
    text-indent: 2em;
    text-align: justify;
  }

  /* 2. 排除不需要缩进的区域 */
  
  /* 提示框 (Callout) 内部通常不缩进，保持对齐更美观 */
  .callout p {
    text-indent: 0;
  }
  
  /* 列表项内部的段落不缩进 */
  li p {
    text-indent: 0;
  }

  /* 交互式图表 (Observable) 产生的文本不缩进，以免破坏 UI 布局 */
  .observablehq p {
    text-indent: 0;
  }
  
  /* 图片和表格的标题不缩进 */
  figure caption, .figure-caption {
    text-indent: 0;
  }
</style>

::: {.callout-note appearance="simple"}
**课程作业信息**

- **学号**：25113060024
- **姓名**：马忠慧
:::

## 数学建模（从正问题到贝叶斯逆问题）

在生物医学图像处理与成像领域中，我们通常将“物理世界到信号的映射”称为正问题，而将“由信号反推物理世界”的过程称为逆问题，将物理世界中真实但不可直接观测的结构记为 $x$，通过成像系统获得的测量信号或图像记为 $y$。二者之间的关系可以用一个最直观的箭头示意来描述：从 $x$ 指向 $y$ 的过程对应正问题，而从 $y$ 指回 $x$ 的过程对应逆问题：

$$
x \xrightarrow{\text{正问题}} y,\qquad
y \xrightarrow{\text{逆问题}} x
$$ {#eq-forward-inverse}

然而，这两个方向并不对称。给定真实世界 $x$ 以及成像系统和物理规律，理论上可以确定性地计算出观测信号 $y$，这种过程我们表示为：

$$
y = A(x) + n,
$$ {#eq-forward-noise}

其中 $A(\cdot)$ 表示正问题算子，例如模糊、遮挡、缺失或下采样等，$n$ 表示噪声项。若进一步假设噪声与信号无关，并服从独立同分布的高斯分布，则有：

$$
n \sim \mathcal{N}(0,\sigma^2 I),
$$ {#eq-gaussian-noise}

* **$n$ (随机向量)**: 这里 $n$ 是一个 $k$ 维列向量，向量的维数与信号空间的y一致。
* **$\mathcal{N}$ (分布族)**: 代表正态（Normal）或高斯（Gaussian）分布族。
* **$0$ (均值向量 $\mu$)**: 这里指的是零向量 $\mathbf{0} \in \mathbb{R}^k$。这意味着噪声是无偏的（Unbiased）。
  $$
  \mathbb{E}[n] = \mathbf{0}
  $$
* **$\sigma^2 I$ (协方差矩阵 $\Sigma$)**: 这是理解该噪声性质的核心。$\Sigma$ 是一个 $k \times k$ 的矩阵，描述了向量各分量之间的方差与相关性。
    * $\sigma^2$: 标量，表示噪声的功率或方差（Variance）。
    * $I$: $k \times k$ 的单位矩阵（Identity Matrix），对角线上为 1，其余为 0。
对于一般的多变量高斯分布 $X \sim \mathcal{N}(\mu, \Sigma)$，其概率密度函数定义为：
$$
f(\mathbf{x}) = \frac{1}{\sqrt{(2\pi)^k |\Sigma|}} \exp\left( -\frac{1}{2} (\mathbf{x} - \mu)^T \Sigma^{-1} (\mathbf{x} - \mu) \right)
$$
其中 $|\Sigma|$ 是协方差矩阵的行列式。针对我们特定的情况 $\mu = \mathbf{0}$ 和 $\Sigma = \sigma^2 I$，我们可以进行如下推导：

1. **行列式计算**:
   $$
   |\Sigma| = |\sigma^2 I| = (\sigma^2)^k |I| = (\sigma^{2})^k
   $$
2. **逆矩阵计算**:
   $$
   \Sigma^{-1} = (\sigma^2 I)^{-1} = \frac{1}{\sigma^2} I^{-1} = \frac{1}{\sigma^2} I
   $$
3. **马哈拉诺比斯距离（Mahalanobis Distance）的退化**:
   指数部分的二次型 $(\mathbf{x} - \mu)^T \Sigma^{-1} (\mathbf{x} - \mu)$ 简化为：
   $$
   \mathbf{x}^T \left( \frac{1}{\sigma^2} I \right) \mathbf{x} = \frac{1}{\sigma^2} \mathbf{x}^T \mathbf{x} = \frac{1}{\sigma^2} \|\mathbf{x}\|_2^2
   $$
   这里 $\|\mathbf{x}\|_2^2 = \sum_{i=1}^k x_i^2$ 是欧几里得范数的平方。
4. **协方差矩阵 $\Sigma = \sigma^2 I$ 的几何与代数意义**:

| 矩阵元素 | 数学定义 | 物理意义 | $\sigma^2 I$ 的情况 |
| :--- | :--- | :--- | :--- |
| **对角线元素** $\Sigma_{ii}$ | $Var(n_i) = \mathbb{E}[(n_i - \mu_i)^2]$ | 第 $i$ 个分量的方差（功率） | 所有分量方差均为 $\sigma^2$ (同分布) |
| **非对角线元素** $\Sigma_{ij} (i \neq j)$ | $Cov(n_i, n_j) = \mathbb{E}[(n_i - \mu_i)(n_j - \mu_j)]$ | 分量 $i$ 与 $j$ 的线性相关性 | 均为 0 (不相关/正态分布下即独立) |

**谱定理与特征分解**:
协方差矩阵是实对称矩阵，根据谱定理（Spectral Theorem），它一定可以正交对角化。对于 $\Sigma = \sigma^2 I$：
* **特征值**: 所有特征值 $\lambda_1, \dots, \lambda_k$ 均等于 $\sigma^2$。
* **特征向量**: 任意一组正交基都可以作为特征向量。


这导致了一个关键的几何性质——**旋转不变性（Rotation Invariance）**。

#### 2.3.1 旋转不变性的严格证明

这是 DDRM 算法能够在谱空间工作的基石。

**命题**: 若随机向量 $n \sim \mathcal{N}(0, \sigma^2 I)$，对于任意 $k \times k$ 的正交矩阵 $Q$（即 $Q^T Q = Q Q^T = I$），变换后的向量 $n' = Q n$ 依然服从分布 $\mathcal{N}(0, \sigma^2 I)$。

**证明**:

1. **线性变换性质**: 高斯变量的线性变换仍为高斯变量。
2. **均值变换**:
   $$
   \mathbb{E}[n'] = \mathbb{E}[Q n] = Q \mathbb{E}[n] = Q \cdot \mathbf{0} = \mathbf{0}
   $$
3. **协方差变换**:
   $$
   \begin{aligned}
   Cov(n') &= \mathbb{E}[(n' - \mathbf{0})(n' - \mathbf{0})^T] \\
           &= \mathbb{E}[(Qn)(Qn)^T] \\
           &= \mathbb{E}[Q n n^T Q^T] \\
           &= Q \mathbb{E}[n n^T] Q^T \\
           &= Q (\sigma^2 I) Q^T \\
           &= \sigma^2 (Q I Q^T) \\
           &= \sigma^2 (Q Q^T) \\
           &= \sigma^2 I
   \end{aligned}
   $$

**结论**: 旋转后的噪声 $n'$ 具有与原噪声完全相同的统计特性。这意味着我们可以在任意正交基（例如线性算子 $H$ 的 SVD 分解中的 $U$ 或 $V$ 矩阵）下分析白噪声，而无需担心改变其分布性质。这解释了为什么 DDRM 可以安全地将图像和噪声投影到谱空间进行处理。




当我们求解逆问题时，仅凭有限、退化且不可避免地受到噪声污染的观测 $y$，往往存在多个不同的 $x$ 都可以生成同一个 $y$。换言之，正问题通常是确定性的，而逆问题在本质上是不确定的。这种不对称性正是成像逆问题困难性的根源。基于这种不对称性，我们更倾向于用概率语言来表达逆问题中“相信程度”的更新。由于同一个观测 $y$ 可能对应多个可能的物理世界 $x$，逆问题的目标便不再适合被表述为“寻找唯一正确的解”。更合理的提法是：在当前可获得的信息条件下，我对不同候选 $x$ 的相信程度分别有多大？基于此，概率模型被引入，逆问题转变为后验分布 $p(x\mid y)$，即在观测到信号 $y$ 之后，对真实世界 $x$ 的相信程度。贝叶斯公式为这一思想提供了严格而统一的数学表达：


$$
p(x | y) = \frac{p(y | x) p(x)}{p(y)}
$$

$$
\text{后验(Posterior)} = \frac{\text{似然(Likelihood)} \times \text{先验(Prior)}}{\text{证据(Evidence)}}
$$

 先验概率 (Prior Probability) $p(x)$ 概括了在观测到任何数据之前，我们对未知信号 $x$ 的所有知识与信念。在图像恢复中， $p(x)$ 代表了“自然图像流形”（Natural Image Manifold）。它定义了什么样的像素排列构成一张合理的自然图像（如边缘的连续性、纹理的统计规律等），并赋予高概率；而对于随机噪声图像，赋予极低的概率。 扩散模型（Diffusion Models）本质上就是一种学习到的先验。通过训练，扩散模型隐式地学习了 $\nabla_x \log p(x)$（得分函数，Score Function）。DDRM 利用这个预训练的强先验来指导恢复过程，确保恢复结果不仅符合观测数据，还具备自然图像的特征。

似然函数描述了假设信号为 $x$ 时，观测到数据 $y$ 的概率密度。它是前向物理模型（Forward Model）的概率描述。

对于线性逆问题：
$$
y = Hx + n, \quad n \sim \mathcal{N}(0, \sigma_y^2 I)
$$

* $H$: 线性退化算子（如模糊核、下采样矩阵、掩膜）。
* $n$: 测量噪声。

由于 $n = y - Hx$，且 $n$ 服从高斯分布，我们可以直接写出似然函数的解析式：

$$
p(y | x) \propto \exp\left( -\frac{\|y - Hx\|^2}{2\sigma_y^2} \right)
$$

 后验分布是贝叶斯推断的终极目标，它融合了先验知识与观测数据，给出了给定观测 $y$ 下 $x$ 的概率分布。

$$
p(x | y) \propto \exp\left( -\frac{\|y - Hx\|^2}{2\sigma_y^2} \right) p(x)
$$

或在对数域中（忽略常数项）：

$$
\log p(x | y) = \log p(x) - \frac{1}{2\sigma_y^2} \|y - Hx\|^2 + C
$$

* 第一项 $\log p(x)$ 推动解向自然图像流形靠拢（正则化）。
* 第二项 $-\frac{1}{2\sigma_y^2} \|y - Hx\|^2$ 推动解符合观测数据（保真度）。
* 系数 $\frac{1}{2\sigma_y^2}$ 起到了拉格朗日乘子（Lagrange Multiplier）的作用，平衡这两股力量。

**DDRM 的核心任务**: DDRM 的目标是从这个复杂的后验分布 $p(x | y)$ 中进行采样。传统的马尔可夫链蒙特卡洛（MCMC）方法在高维空间效率极低，而扩散模型提供了一种高效的采样路径。

### 3.5 边缘似然/证据 (Marginal Likelihood) $p(y)$

分母 $p(y) = \int p(y|x)p(x) dx$ 是对所有可能的 $x$ 进行积分。在高维空间中，这个积分通常是不可计算的（Intractable）。

* **变分推断（Variational Inference）**: 为了绕过直接计算 $p(y)$，DDRM 借用了变分推断的思想，通过优化证据下界（ELBO, Evidence Lower Bound）来近似后验分布。


```{ojs}
viewof mu = Inputs.range([-5, 5], { value: 0, step: 0.01, label: "μ (mean)" })
viewof sigma = Inputs.range([0.1, 3], { value: 1, step: 0.01, label: "σ (std dev)" })

// 1. 直接在这里显示文本，方差直接在 ${} 里计算，不需要单独定义变量
md`当前参数: μ=${mu.toFixed(2)}, σ=${sigma.toFixed(2)}, σ²=${(sigma * sigma).toFixed(2)}`

// 2. 复杂的计算和绘图逻辑，必须用 { } 包裹起来作为一个整体
{
  const xMin = -4
  const xMax = 4
  
  // 生成数据
  const data = Array.from({ length: 800 }, (_, i) => {
    const x = xMin + (xMax - xMin) * (i / 799)
    const z = (x - mu) / sigma
    const y = Math.exp(-0.5 * z * z) / (sigma * Math.sqrt(2 * Math.PI))
    return { x, y }
  })

  // 绘图
  return Plot.plot({
    width: 720,
    height: 360,
    grid: true,
    x: { label: "x", domain: [xMin, xMax] },
    y: { label: "p(x)", domain: [0, 2] }, // 建议固定Y轴，效果更好
    marks: [
      Plot.line(data, { x: "x", y: "y", strokeWidth: 2 }),
      Plot.ruleY([0])
    ]
  })
}
```
